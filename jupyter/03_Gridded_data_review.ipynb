{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c0e5285",
   "metadata": {},
   "source": [
    "# Gridded data review\n",
    "\n",
    "**Description:**   \n",
    "This script is part of the annual gridded data review for CLRTAP (starting with 2024 on GNFR E_Solvents and NMVOC).\n",
    "\n",
    "**Original Author:** Marco Pizzolato    \n",
    "**Date:**  April 2024   \n",
    "**Maintainer:** Christopher Evangelides      \n",
    "**Date:** June 2024    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab37303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from configparser import ConfigParser\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.io.sql as sqlio\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import psycopg2\n",
    "from psycopg2 import Error\n",
    "import sqlalchemy as db\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams as rc\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0dd179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the credentials with the correct path\n",
    "  \n",
    "def initiate_engine(filename_sqlalchemy):\n",
    "    '''Takes the txt file with the parameters to connect to \n",
    "    the database, example: postgresql://user:password@localhost/database \n",
    "    and return the engine to connect to the database.'''\n",
    "    user = os.getlogin()\n",
    "    root_path = os.path.join(r'C:\\Users',user,\"db_credentials\")\n",
    "    sqlalchemy_filename_path = os.path.join(root_path, filename_sqlalchemy)\n",
    "    # Load the credentials with the correct path\n",
    "    if os.path.exists(sqlalchemy_filename_path):\n",
    "        with open(sqlalchemy_filename_path) as f:\n",
    "            lines = f.readlines()\n",
    "            engine = db.create_engine(lines[0])\n",
    "    return engine\n",
    "engine = initiate_engine('sqlalchemy_engine_gisdata.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28c85a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test connection\n",
    "poll = \"NMVOC\"\n",
    "country_iso2 = \"AT\"\n",
    "\n",
    "austrian_emissions_query = \"SELECT a.lonlat, SUM(a.emission_t) as \\\"E_Solvents\\\", a.\\\"ISO2\\\", a.YEAR, a.pollutant_code, a.units FROM clrtap.reported_nmvoc_e_solvents a INNER JOIN clrtap.cams_nmvoc_e_solvents b ON a.geom = b.geom WHERE a.pollutant_code = '\"+poll+\"' AND a.\\\"ISO2\\\" = '\"+country_iso2+\"' AND a.\\\"ISO2\\\" = b.\\\"ISO2\\\" GROUP BY a.lonlat, a.\\\"ISO2\\\", a.YEAR, a.pollutant_code, a.units ORDER BY a.lonlat;\"\n",
    "austrian_emissions = pd.read_sql_query(austrian_emissions_query, con=engine) \n",
    "austrian_emissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a6ac79",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8656da",
   "metadata": {},
   "outputs": [],
   "source": [
    "iso2_dict = {\n",
    "    \"Austria\": \"AT\", \"Belgium\": \"BE\", \"Bulgaria\": \"BG\", \"Switzerland\": \"CH\", \"Cyprus\": \"CY\",\n",
    "    \"Czech Republic\": \"CZ\", \"Germany\": \"DE\", \"Denmark\": \"DK\", \"Estonia\": \"EE\", \"Spain\": \"ES\",\n",
    "    \"Finland\": \"FI\", \"France\": \"FR\", \"United Kingdom\": \"GB\", \"Georgia\": \"GE\", \"Greece\": \"GR\",\n",
    "    \"Croatia\": \"HR\", \"Hungary\": \"HU\", \"Ireland\": \"IE\", \"Italy\": \"IT\", \"Lithuania\": \"LT\",\n",
    "    \"Luxembourg\": \"LU\", \"Latvia\": \"LV\", \"Monaco\": \"MC\", \"North Macedonia\": \"MK\", \"Malta\": \"MT\",\n",
    "    \"Netherlands\": \"NL\", \"Norway\": \"NO\", \"Poland\": \"PL\", \"Portugal\": \"PT\", \"Romania\": \"RO\",\n",
    "    \"Serbia\": \"RS\", \"Russia\": \"RU\", \"Sweden\": \"SE\", \"Slovenia\": \"SI\", \"Slovakia\": \"SK\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79b743a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iso2_dict = {\"Austria\": \"AT\", \"Belgium\": \"BE\", \"Bulgaria\": \"BG\", \"Switzerland\": \"CH\", \"Cyprus\": \"CY\"}\n",
    "\n",
    "iso2_dict = {\"Serbia\": \"RS\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb83f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAMS\n",
    "def query_poll_cams (poll, country_iso2):\n",
    "    sql_cams = \"SELECT a.lonlat, SUM(a.emission_t) as \\\"E_Solvents\\\", a.\\\"ISO2\\\", a.YEAR, a.pollutant_code, a.units FROM clrtap.cams_nmvoc_e_solvents a INNER JOIN clrtap.reported_nmvoc_e_solvents b ON a.geom = b.geom WHERE a.pollutant_code = '\"+poll+\"' AND a.\\\"ISO2\\\" = '\"+country_iso2+\"' AND a.\\\"ISO2\\\" = b.\\\"ISO2\\\" GROUP BY a.lonlat, a.\\\"ISO2\\\", a.YEAR, a.pollutant_code, a.units ORDER BY a.lonlat;\"\n",
    "    return sql_cams\n",
    "\n",
    "# Reported\n",
    "def query_poll_reported (poll, country_iso2):\n",
    "    sql_reported = \"SELECT a.lonlat, SUM(a.emission_t) as \\\"E_Solvents\\\", a.\\\"ISO2\\\", a.YEAR, a.pollutant_code, a.units FROM clrtap.reported_nmvoc_e_solvents a INNER JOIN clrtap.cams_nmvoc_e_solvents b ON a.geom = b.geom WHERE a.pollutant_code = '\"+poll+\"' AND a.\\\"ISO2\\\" = '\"+country_iso2+\"' AND a.\\\"ISO2\\\" = b.\\\"ISO2\\\" GROUP BY a.lonlat, a.\\\"ISO2\\\", a.YEAR, a.pollutant_code, a.units ORDER BY a.lonlat;\"\n",
    "    return sql_reported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80c3733",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prepare table for out of the loop\n",
    "df_var = {'pollutant': [''],\n",
    "          'gnfr': [''],\n",
    "          'country_iso2': [''],\n",
    "          'year': [''],\n",
    "          'R2': [''],\n",
    "          'R2adj': [''],\n",
    "          'obs': ['']}\n",
    "\n",
    "\n",
    "poll_list = ['NMVOC']\n",
    "\n",
    "gnfr_list = [\"A_PublicPower\",\"B_Industry\",\"C_OtherStationaryComb\",\"D_Fugitive\",\"E_Solvents\",\"F_RoadTransport\", \"G_Shipping\",\"H_Aviation\",\"I_Offroad\",\"J_Waste\",\"K_AgriLivestock\",\"L_AgriOther\"]\n",
    "gnfr_list = [\"E_Solvents\"]\n",
    "\n",
    "for ccountry in iso2_dict.keys():\n",
    "#     print(iso2_dict[ccountry])\n",
    "#     print(iso3_dict[ccountry])\n",
    "\n",
    "    country_iso2 = iso2_dict[ccountry]\n",
    "#     country_iso3 = iso2_dict[ccountry]\n",
    "\n",
    "    \n",
    "    for poll in poll_list:\n",
    "\n",
    "\n",
    "        # Retrieve Reported\n",
    "\n",
    "        sql_reported = query_poll_reported(poll, country_iso2)\n",
    "        data_reported = sqlio.read_sql_query(sql_reported, con=engine)\n",
    "\n",
    "        # data_reported = data_reported.drop(columns=[\"year\", \"units\",\"x\",\"y\"])\n",
    "\n",
    "\n",
    "        # Retrieve CAMS\n",
    "\n",
    "        sql_cams = query_poll_cams(poll, country_iso2)\n",
    "        data_cams = sqlio.read_sql_query(sql_cams, con=engine)\n",
    "\n",
    "        # data_cams = data_cams.drop(columns=[\"x\",\"y\",\"year\",\"units\"])\n",
    "\n",
    "        dataTypeSeries = data_cams.dtypes\n",
    "        # print('Data type of each column of Dataframe :')\n",
    "        # print(dataTypeSeries)\n",
    "\n",
    "\n",
    "\n",
    "        # JOIN\n",
    "\n",
    "        ## Merge the two datasets\n",
    "        merge_df = pd.merge(data_reported, data_cams, on='lonlat', how='outer',suffixes = [\"_r\",\"_c\"])\n",
    "\n",
    "        ## Change NAs to 0\n",
    "        merge_df = merge_df.fillna(0)\n",
    "\n",
    "        ## In case methodology changes and you want to drop the NAs..\n",
    "        # merge_df.dropna(inplace=True)\n",
    "        # merge_df.fillna(0)\n",
    "\n",
    "        if len(merge_df['lonlat']) != len(data_reported['lonlat']):  #.unique\n",
    "            print(\"Hey! There might be an issue here! Check the merging between the datasets!\")\n",
    "            print(\"Length of reported is  \" + str(len(data_reported['lonlat'])))\n",
    "            print(\"Length of merged_df is  \" + str(len(merge_df['lonlat'])))\n",
    "            print(\"Length of cams is  \" + str(len(data_reported['lonlat'])))\n",
    "\n",
    "        else:\n",
    "            print(\"Length of merged_df is \" + str(len(merge_df['lonlat'])))\n",
    "\n",
    "        # INITIATE THE TABLE\n",
    "        country = country_iso2\n",
    "        ## Make a copy of the dataset\n",
    "        merge_df2 = merge_df\n",
    "        \n",
    "        for gnfr in gnfr_list:\n",
    "            \n",
    "            ## Loop\n",
    "            c_gnfr = gnfr + \"_c\"\n",
    "            r_gnfr = gnfr + \"_r\"\n",
    "\n",
    "            if (merge_df2[r_gnfr].sum() != 0) & (merge_df2[r_gnfr].sum() != 0):\n",
    "            \n",
    "                stats = pd.DataFrame(df_var, columns = ['pollutant','R2','R2adj','obs','country_iso2'])\n",
    "                stats['pollutant'] = poll\n",
    "                stats['country_iso2'] = country_iso2\n",
    "                stats['gnfr'] = gnfr\n",
    "\n",
    "\n",
    "                ## Create the regression model\n",
    "                regression = smf.ols(str(c_gnfr+\"~\"+r_gnfr), merge_df2)\n",
    "                ols_fit = regression.fit()\n",
    "                # All the results in detail (it can be printed)\n",
    "                ols_res = ols_fit.summary()\n",
    "\n",
    "                # print(ols_res.summary())\n",
    "\n",
    "                print(\"Results for: \"+poll)\n",
    "                print(\"R2    \" + str(round(ols_fit.rsquared,2)))\n",
    "                print(ccountry)\n",
    "#                 print(\"R2adj \" + str(round(ols_fit.rsquared_adj,2)))\n",
    "                print(\"n.obs \" + str(int(ols_fit.nobs)))\n",
    "\n",
    "                stats[\"R2\"] = (round(ols_fit.rsquared,2))\n",
    "                stats[\"R2adj\"] = (round(ols_fit.rsquared_adj,2))\n",
    "                stats[\"obs\"] = (int(ols_fit.nobs))\n",
    "#                 stats_tot = stats_tot.append(stats)\n",
    "\n",
    "                # Add column with fitted values and residuals\n",
    "                merge_df2[('yhat_'+poll)] = ols_fit.fittedvalues\n",
    "                merge_df2[('res_'+poll)] = ols_fit.resid\n",
    "\n",
    "                std_res = merge_df2[('res_'+poll)].std()\n",
    "                merge_df2[('res_std_'+poll)] = merge_df2[('res_'+poll)]/std_res\n",
    "\n",
    "\n",
    "                flag_res_h = merge_df2[(merge_df2[\"res_std_\"+poll] >= 3)]\n",
    "                flag_res_l = merge_df2[(merge_df2[\"res_std_\"+poll] <= -3)]\n",
    "\n",
    "\n",
    "                # best fit polynomials\n",
    "\n",
    "                c_array = merge_df2[c_gnfr]\n",
    "                r_array = merge_df2[r_gnfr]\n",
    "\n",
    "                # Calculate the polynomial that fits\n",
    "                merge_fit = np.polyfit(r_array, c_array, 1)\n",
    "\n",
    "                ### Plot\n",
    "                # Get the right positon for the formula\n",
    "                max_val1 = merge_df2[c_gnfr].max()\n",
    "                max_val2 = merge_df2[r_gnfr].max()\n",
    "                up_pos = max_val1 * 0.18\n",
    "                right_pos = max_val2 * 0.75\n",
    "                up_pos2 = max_val1 * 0.25\n",
    "                right_pos2 = max_val2 * 0.75\n",
    "                up_pos3 = max_val1 * 0.32\n",
    "                right_pos3 = max_val2 * 0.75\n",
    "\n",
    "                c_poll = c_gnfr\n",
    "                r_poll = r_gnfr\n",
    "\n",
    "                rc['font.family'] = \"sans-serif\"\n",
    "                font = \"Roboto\"\n",
    "                # Scatter plots\n",
    "                marker_size = 100\n",
    "                ax1 = merge_df2.plot(kind='scatter', x=r_poll, y=c_poll, color='mediumblue', alpha=0.4, marker='x',s=30,figsize=(10 ,7))\n",
    "                ax2 = flag_res_l.plot(kind='scatter', x=r_poll, y=c_poll, color='darkmagenta', alpha=1, marker='D', s=50, figsize=(10,7), ax=ax1)\n",
    "                flag_res_h.plot(kind='scatter', x=r_poll, y=c_poll, color='crimson', alpha=1, marker='o',s=50,figsize=(10 ,7), ax=ax2)\n",
    "\n",
    "                # # regression lines\n",
    "                plt.plot(merge_df2[c_poll], merge_fit[0] * merge_df2[c_poll] + merge_fit[1], color='mediumblue', linewidth=0.4)\n",
    "\n",
    "                # # regression equations\n",
    "                plt.text(right_pos, up_pos , 'y={:.0f}+{:.2f}*x'.format(merge_fit[1], merge_fit[0]), color='mediumblue', alpha=0.8, fontname=\"Computer Modern\", size=16)\n",
    "                R2adj = (\"R² = \" + str(round(ols_fit.rsquared,2)))\n",
    "                plt.text(right_pos2, up_pos2, R2adj, color='mediumblue', alpha=0.8, fontname=\"Computer Modern\", size=16)\n",
    "                obs = (\"n.obs = \" + str(int(ols_fit.nobs)))\n",
    "                plt.text(right_pos3, up_pos3, obs, color='mediumblue', alpha=0.8, fontname=\"Computer Modern\", size=16)\n",
    "\n",
    "\n",
    "                # # legend, title and labels.\n",
    "                plt.legend(labels=['Emissions in ±3std','Emissions  <= 3std', 'Emissions  >= 3std', 'Regresion Line' ], loc=\"lower right\")\n",
    "                \n",
    "                # Initialize an empty set to store unique values of 'year_r'\n",
    "                unique_years = set()\n",
    "\n",
    "                # Loop through each row in the DataFrame\n",
    "                for index, row in merge_df2.iterrows():\n",
    "                    year_r_value = row['year_r']\n",
    "\n",
    "                    # Sub if-statement to check and add unique values\n",
    "                    if year_r_value not in unique_years:\n",
    "                        unique_years.add(year_r_value)\n",
    "\n",
    "                # Convert the set to a sorted list for better readability (optional)\n",
    "                unique_years = sorted(unique_years)\n",
    "                # print(unique_years)\n",
    "                \n",
    "                for year in unique_years:           \n",
    "                \n",
    "                    plt.title(('OLS-regression Reported-CAMS ' + poll + ' ' + str(year) + ' emissions (' + ccountry + ')'), fontname=font, size=20, pad=12)\n",
    "                    plt.ylabel('CAMS (t)', fontname=font, size=15)\n",
    "                    plt.xlabel('Reported (t)', fontname=font, size=15)\n",
    "\n",
    "                    out_path1 = os.path.join(\"Q:/Delivery/GISdata/CLRTAP/Plots/\" + \"ols_resid_\"+ccountry+\"_\"+ str(year) + \"_\"+gnfr+\"_\"+poll+\".png\") #### CHRIS BRING BACK IN\n",
    "                    plt.savefig(out_path1 , dpi=150) # save as png\n",
    "                    plt.show()\n",
    "\n",
    "                    export_df = merge_df2\n",
    "                    export_df[['longitude', 'latitude']] = export_df['lonlat'].str.split(',', expand=True)\n",
    "                    export_df = export_df.rename(columns={\n",
    "                        r_gnfr: gnfr+'_emissions_reported',\n",
    "                        c_gnfr: gnfr+'_emissions_CAMS',\n",
    "                        'year_r':'year',\n",
    "                        'pollutant_code_r':'pollutant',\n",
    "                        'units_r':'units_reported',\n",
    "                        'units_c':'units_CAMS',\n",
    "                        'ISO2_r':'country',\n",
    "                        'res_' + poll: 'residual_' + poll,\n",
    "                        'res_std_' + poll: 'residual_std_' + poll\n",
    "                    })\n",
    "\n",
    "                    export_df['country'] = ccountry\n",
    "                    export_df['units_reported'] = 'tonnes'\n",
    "                    export_df['units_CAMS'] = 'tonnes'\n",
    "                    export_df = export_df.drop(columns=['pollutant_code_c', 'yhat_' + poll, 'ISO2_c', 'year_c', 'lonlat'])\n",
    "                    new_column_order = ['country',\n",
    "                                       'year',\n",
    "                                       'pollutant',\n",
    "                                       'longitude',\n",
    "                                       'latitude',\n",
    "                                       gnfr+'_emissions_reported',\n",
    "                                       'units_reported',\n",
    "                                       gnfr+'_emissions_CAMS',\n",
    "                                       'units_CAMS',\n",
    "                                       'residual_' + poll,\n",
    "                                       'residual_std_' + poll] \n",
    "                    export_df = export_df[new_column_order]\n",
    "#                   export_df\n",
    "                    \n",
    "                    # Save the DataFrame to CSV\n",
    "                    out_csv_path = os.path.join(\"Q:/Delivery/GISdata/CLRTAP/Plots/\" + \"data_\"+ccountry+\"_\"+ str(year) + \"_\"+gnfr+\"_\"+poll+\".csv\")\n",
    "#                     print(\"csv exported!\")\n",
    "                    export_df.to_csv(out_csv_path, index=False)\n",
    "\n",
    "#                     print(\"done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e976c8",
   "metadata": {},
   "source": [
    "## Serbia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9556f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "iso2_dict = {\"Serbia\": \"RS\"}\n",
    "# Prepare table for out of the loop\n",
    "df_var = {'pollutant': [''],\n",
    "          'gnfr': [''],\n",
    "          'country_iso2': [''],\n",
    "          'year': [''],\n",
    "          'R2': [''],\n",
    "          'R2adj': [''],\n",
    "          'obs': ['']}\n",
    "\n",
    "\n",
    "poll_list = ['NMVOC']\n",
    "\n",
    "gnfr_list = [\"A_PublicPower\",\"B_Industry\",\"C_OtherStationaryComb\",\"D_Fugitive\",\"E_Solvents\",\"F_RoadTransport\", \"G_Shipping\",\"H_Aviation\",\"I_Offroad\",\"J_Waste\",\"K_AgriLivestock\",\"L_AgriOther\"]\n",
    "gnfr_list = [\"E_Solvents\"]\n",
    "\n",
    "for ccountry in iso2_dict.keys():\n",
    "#     print(iso2_dict[ccountry])\n",
    "#     print(iso3_dict[ccountry])\n",
    "\n",
    "    country_iso2 = iso2_dict[ccountry]\n",
    "#     country_iso3 = iso2_dict[ccountry]\n",
    "\n",
    "    \n",
    "    for poll in poll_list:\n",
    "\n",
    "\n",
    "        # Retrieve Reported\n",
    "\n",
    "        sql_reported = query_poll_reported(poll, country_iso2)\n",
    "        data_reported = sqlio.read_sql_query(sql_reported, con=engine)\n",
    "\n",
    "        # data_reported = data_reported.drop(columns=[\"year\", \"units\",\"x\",\"y\"])\n",
    "\n",
    "\n",
    "        # Retrieve CAMS\n",
    "\n",
    "        sql_cams = query_poll_cams(poll, country_iso2)\n",
    "        data_cams = sqlio.read_sql_query(sql_cams, con=engine)\n",
    "\n",
    "        # data_cams = data_cams.drop(columns=[\"x\",\"y\",\"year\",\"units\"])\n",
    "\n",
    "        dataTypeSeries = data_cams.dtypes\n",
    "        # print('Data type of each column of Dataframe :')\n",
    "        # print(dataTypeSeries)\n",
    "\n",
    "\n",
    "\n",
    "        # JOIN\n",
    "\n",
    "        ## Merge the two datasets\n",
    "        merge_df = pd.merge(data_reported, data_cams, on='lonlat', how='outer',suffixes = [\"_r\",\"_c\"])\n",
    "\n",
    "        ## Change NAs to 0\n",
    "        merge_df = merge_df.fillna(0)\n",
    "\n",
    "        ## In case methodology changes and you want to drop the NAs..\n",
    "        # merge_df.dropna(inplace=True)\n",
    "        # merge_df.fillna(0)\n",
    "\n",
    "        if len(merge_df['lonlat']) != len(data_reported['lonlat']):  #.unique\n",
    "            print(\"Hey! There might be an issue here! Check the merging between the datasets!\")\n",
    "            print(\"Length of reported is  \" + str(len(data_reported['lonlat'])))\n",
    "            print(\"Length of merged_df is  \" + str(len(merge_df['lonlat'])))\n",
    "            print(\"Length of cams is  \" + str(len(data_reported['lonlat'])))\n",
    "\n",
    "        else:\n",
    "            print(\"Length of merged_df is \" + str(len(merge_df['lonlat'])))\n",
    "\n",
    "        # INITIATE THE TABLE\n",
    "        country = country_iso2\n",
    "        ## Make a copy of the dataset\n",
    "        merge_df2 = merge_df\n",
    "        \n",
    "        for gnfr in gnfr_list:\n",
    "            \n",
    "            ## Loop\n",
    "            c_gnfr = gnfr + \"_c\"\n",
    "            r_gnfr = gnfr + \"_r\"\n",
    "\n",
    "            if (merge_df2[r_gnfr].sum() != 0) & (merge_df2[r_gnfr].sum() != 0):\n",
    "            \n",
    "                stats = pd.DataFrame(df_var, columns = ['pollutant','R2','R2adj','obs','country_iso2'])\n",
    "                stats['pollutant'] = poll\n",
    "                stats['country_iso2'] = country_iso2\n",
    "                stats['gnfr'] = gnfr\n",
    "\n",
    "\n",
    "                ## Create the regression model\n",
    "                regression = smf.ols(str(c_gnfr+\"~\"+r_gnfr), merge_df2)\n",
    "                ols_fit = regression.fit()\n",
    "                # All the results in detail (it can be printed)\n",
    "                ols_res = ols_fit.summary()\n",
    "\n",
    "                # print(ols_res.summary())\n",
    "\n",
    "                print(\"Results for: \"+poll)\n",
    "                print(\"R2    \" + str(round(ols_fit.rsquared,2)))\n",
    "                print(ccountry)\n",
    "#                 print(\"R2adj \" + str(round(ols_fit.rsquared_adj,2)))\n",
    "                print(\"n.obs \" + str(int(ols_fit.nobs)))\n",
    "\n",
    "                stats[\"R2\"] = (round(ols_fit.rsquared,2))\n",
    "                stats[\"R2adj\"] = (round(ols_fit.rsquared_adj,2))\n",
    "                stats[\"obs\"] = (int(ols_fit.nobs))\n",
    "#                 stats_tot = stats_tot.append(stats)\n",
    "\n",
    "                # Add column with fitted values and residuals\n",
    "                merge_df2[('yhat_'+poll)] = ols_fit.fittedvalues\n",
    "                merge_df2[('res_'+poll)] = ols_fit.resid\n",
    "\n",
    "                std_res = merge_df2[('res_'+poll)].std()\n",
    "                merge_df2[('res_std_'+poll)] = merge_df2[('res_'+poll)]/std_res\n",
    "\n",
    "\n",
    "                flag_res_h = merge_df2[(merge_df2[\"res_std_\"+poll] >= 3)]\n",
    "                flag_res_l = merge_df2[(merge_df2[\"res_std_\"+poll] <= -3)]\n",
    "\n",
    "\n",
    "                # best fit polynomials\n",
    "\n",
    "                c_array = merge_df2[c_gnfr]\n",
    "                r_array = merge_df2[r_gnfr]\n",
    "\n",
    "                # Calculate the polynomial that fits\n",
    "                merge_fit = np.polyfit(r_array, c_array, 1)\n",
    "\n",
    "                ### Plot\n",
    "                # Get the right positon for the formula\n",
    "                max_val1 = merge_df2[c_gnfr].max()\n",
    "                max_val2 = merge_df2[r_gnfr].max()\n",
    "                up_pos = max_val1 * 0.2\n",
    "                right_pos = max_val2 * 1.5\n",
    "                up_pos2 = max_val1 * 0.3\n",
    "                right_pos2 = max_val2 * 1.5\n",
    "                up_pos3 = max_val1 * 0.4\n",
    "                right_pos3 = max_val2 * 1.5\n",
    "\n",
    "                c_poll = c_gnfr\n",
    "                r_poll = r_gnfr\n",
    "\n",
    "                rc['font.family'] = \"sans-serif\"\n",
    "                font = \"Roboto\"\n",
    "                # Scatter plots\n",
    "                marker_size = 100\n",
    "                ax1 = merge_df2.plot(kind='scatter', x=r_poll, y=c_poll, color='mediumblue', alpha=0.4, marker='x',s=30,figsize=(10 ,7))\n",
    "                ax2 = flag_res_l.plot(kind='scatter', x=r_poll, y=c_poll, color='darkmagenta', alpha=1, marker='D', s=50, figsize=(10,7), ax=ax1)\n",
    "                flag_res_h.plot(kind='scatter', x=r_poll, y=c_poll, color='crimson', alpha=1, marker='o',s=50,figsize=(10 ,7), ax=ax2)\n",
    "\n",
    "                # # regression lines\n",
    "                plt.plot(merge_df2[c_poll], merge_fit[0] * merge_df2[c_poll] + merge_fit[1], color='mediumblue', linewidth=0.4)\n",
    "\n",
    "                # # regression equations\n",
    "                plt.text(right_pos, up_pos , 'y={:.0f}+{:.2f}*x'.format(merge_fit[1], merge_fit[0]), color='mediumblue', alpha=0.8, fontname=\"Computer Modern\", size=16)\n",
    "                R2adj = (\"R² = \" + str(round(ols_fit.rsquared,2)))\n",
    "                plt.text(right_pos2, up_pos2, R2adj, color='mediumblue', alpha=0.8, fontname=\"Computer Modern\", size=16)\n",
    "                obs = (\"n.obs = \" + str(int(ols_fit.nobs)))\n",
    "                plt.text(right_pos3, up_pos3, obs, color='mediumblue', alpha=0.8, fontname=\"Computer Modern\", size=16)\n",
    "\n",
    "\n",
    "                # # legend, title and labels.\n",
    "                plt.legend(labels=['Emissions in ±3std','Emissions  <= 3std', 'Emissions  >= 3std', 'Regresion Line' ], loc=\"lower right\")\n",
    "                \n",
    "                # Initialize an empty set to store unique values of 'year_r'\n",
    "                unique_years = set()\n",
    "\n",
    "                # Loop through each row in the DataFrame\n",
    "                for index, row in merge_df2.iterrows():\n",
    "                    year_r_value = row['year_r']\n",
    "\n",
    "                    # Sub if-statement to check and add unique values\n",
    "                    if year_r_value not in unique_years:\n",
    "                        unique_years.add(year_r_value)\n",
    "\n",
    "                # Convert the set to a sorted list for better readability (optional)\n",
    "                unique_years = sorted(unique_years)\n",
    "                # print(unique_years)\n",
    "                \n",
    "                for year in unique_years:           \n",
    "                \n",
    "                    plt.title(('OLS-regression Reported-CAMS ' + poll + ' ' + str(year) + ' emissions (' + ccountry + ')'), fontname=font, size=20, pad=12)\n",
    "                    plt.ylabel('CAMS (t)', fontname=font, size=15)\n",
    "                    plt.xlabel('Reported (t)', fontname=font, size=15)\n",
    "\n",
    "                    out_path1 = os.path.join(\"Q:/Delivery/GISdata/CLRTAP/Plots/\" + \"ols_resid_\"+ccountry+\"_\"+ str(year) + \"_\"+gnfr+\"_\"+poll+\".png\") #### CHRIS BRING BACK IN\n",
    "                    plt.savefig(out_path1 , dpi=150) # save as png\n",
    "                    plt.show()\n",
    "                    \n",
    "                    export_df = merge_df2\n",
    "                    export_df[['longitude', 'latitude']] = export_df['lonlat'].str.split(',', expand=True)\n",
    "                    export_df = export_df.rename(columns={\n",
    "                        r_gnfr: gnfr+'_emissions_reported',\n",
    "                        c_gnfr: gnfr+'_emissions_CAMS',\n",
    "                        'year_r':'year',\n",
    "                        'pollutant_code_r':'pollutant',\n",
    "                        'units_r':'units_reported',\n",
    "                        'units_c':'units_CAMS',\n",
    "                        'ISO2_r':'country',\n",
    "                        'res_' + poll: 'residual_' + poll,\n",
    "                        'res_std_' + poll: 'residual_std_' + poll\n",
    "                    })\n",
    "\n",
    "                    export_df['country'] = ccountry\n",
    "                    export_df['units_reported'] = 'tonnes'\n",
    "                    export_df['units_CAMS'] = 'tonnes'\n",
    "                    export_df = export_df.drop(columns=['pollutant_code_c', 'yhat_' + poll, 'ISO2_c', 'year_c', 'lonlat'])\n",
    "                    new_column_order = ['country',\n",
    "                                       'year',\n",
    "                                       'pollutant',\n",
    "                                       'longitude',\n",
    "                                       'latitude',\n",
    "                                       gnfr+'_emissions_reported',\n",
    "                                       'units_reported',\n",
    "                                       gnfr+'_emissions_CAMS',\n",
    "                                       'units_CAMS',\n",
    "                                       'residual_' + poll,\n",
    "                                       'residual_std_' + poll] \n",
    "                    export_df = export_df[new_column_order]\n",
    "#                   export_df\n",
    "                    \n",
    "                    # Save the DataFrame to CSV\n",
    "                    out_csv_path = os.path.join(\"Q:/Delivery/GISdata/CLRTAP/Plots/\" + \"data_\"+ccountry+\"_\"+ str(year) + \"_\"+gnfr+\"_\"+poll+\".csv\")\n",
    "#                     print(\"csv exported!\")\n",
    "                    export_df.to_csv(out_csv_path, index=False)\n",
    "\n",
    "#                     print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c854c085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export_df = merge_df2\n",
    "# export_df[['longitude', 'latitude']] = export_df['lonlat'].str.split(',', expand=True)\n",
    "# export_df = export_df.rename(columns={\n",
    "#     r_gnfr: gnfr+'_emissions_reported',\n",
    "#     c_gnfr: gnfr+'_emissions_CAMS',\n",
    "#     'year_r':'year',\n",
    "#     'pollutant_code_r':'pollutant',\n",
    "#     'units_r':'units_reported',\n",
    "#     'units_c':'units_CAMS',\n",
    "#     'ISO2_r':'country',\n",
    "#     'res_' + poll: 'residual_' + poll,\n",
    "#     'res_std_' + poll: 'residual_std_' + poll\n",
    "# })\n",
    "\n",
    "# export_df['country'] = ccountry\n",
    "# export_df['units_reported'] = 'tonnes'\n",
    "# export_df = export_df.drop(columns=['pollutant_code_c', 'yhat_' + poll, 'ISO2_c', 'year_c', 'lonlat'])\n",
    "# new_column_order = ['country',\n",
    "#                    'year',\n",
    "#                    'pollutant',\n",
    "#                    'longitude',\n",
    "#                    'latitude',\n",
    "#                    gnfr+'_emissions_reported',\n",
    "#                    'units_reported',\n",
    "#                    gnfr+'_emissions_CAMS',\n",
    "#                    'units_CAMS',\n",
    "#                    'residual_' + poll,\n",
    "#                    'residual_std_' + poll] \n",
    "# export_df = export_df[new_column_order]\n",
    "# # export_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6210dcd",
   "metadata": {},
   "source": [
    "# LPS chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4efa276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare table for out of the loop\n",
    "df_var = {'pollutant': [''],\n",
    "          'gnfr': [''],\n",
    "          'country_iso2': [''],\n",
    "          'country_iso2': [''],\n",
    "          'R2': [''],\n",
    "          'R2adj': [''],\n",
    "          'obs': ['']}\n",
    "\n",
    "\n",
    "poll_list = ['NMVOC']\n",
    "\n",
    "gnfr_list = [\"A_PublicPower\",\"B_Industry\",\"C_OtherStationaryComb\",\"D_Fugitive\",\"E_Solvents\",\"F_RoadTransport\", \"G_Shipping\",\"H_Aviation\",\"I_Offroad\",\"J_Waste\",\"K_AgriLivestock\",\"L_AgriOther\"]\n",
    "gnfr_list = [\"E_Solvents\"]\n",
    "\n",
    "for ccountry in iso2_dict.keys():\n",
    "#     print(iso2_dict[ccountry])\n",
    "#     print(iso3_dict[ccountry])\n",
    "\n",
    "    country_iso2 = iso2_dict[ccountry]\n",
    "    country_iso3 = iso2_dict[ccountry]\n",
    "\n",
    "    \n",
    "    for poll in poll_list:\n",
    "\n",
    "\n",
    "        # Retrieve Reported\n",
    "\n",
    "        sql_reported = query_poll_reported(poll, country_iso2)\n",
    "        data_reported = sqlio.read_sql_query(sql_reported, con=engine)\n",
    "\n",
    "        # data_reported = data_reported.drop(columns=[\"year\", \"units\",\"x\",\"y\"])\n",
    "\n",
    "\n",
    "        # Retrieve CAMS\n",
    "\n",
    "        sql_cams = query_poll_cams(poll, country_iso2)\n",
    "        data_cams = sqlio.read_sql_query(sql_cams, con=engine)\n",
    "\n",
    "        # data_cams = data_cams.drop(columns=[\"x\",\"y\",\"year\",\"units\"])\n",
    "\n",
    "        dataTypeSeries = data_cams.dtypes\n",
    "        # print('Data type of each column of Dataframe :')\n",
    "        # print(dataTypeSeries)\n",
    "\n",
    "\n",
    "\n",
    "        # JOIN\n",
    "\n",
    "        ## Merge the two datasets\n",
    "        merge_df = pd.merge(data_reported, data_cams, on='lonlat', how='outer',suffixes = [\"_r\",\"_c\"])\n",
    "\n",
    "        ## Change NAs to 0\n",
    "        merge_df = merge_df.fillna(0)\n",
    "\n",
    "        ## In case methodology changes and you want to drop the NAs..\n",
    "        # merge_df.dropna(inplace=True)\n",
    "        # merge_df.fillna(0)\n",
    "\n",
    "        if len(merge_df['lonlat']) != len(data_reported['lonlat']):  #.unique\n",
    "            print(\"Hey! There might be an issue here! Check the merging between the datasets!\")\n",
    "            print(\"Length of reported is  \" + str(len(data_reported['lonlat'])))\n",
    "            print(\"Length of merged_df is  \" + str(len(merge_df['lonlat'])))\n",
    "            print(\"Length of cams is  \" + str(len(data_reported['lonlat'])))\n",
    "\n",
    "        else:\n",
    "            print(\"Length of merged_df is \" + str(len(merge_df['lonlat'])))\n",
    "\n",
    "        # INITIATE THE TABLE\n",
    "        country = country_iso2\n",
    "        ## Make a copy of the dataset\n",
    "        merge_df2 = merge_df\n",
    "        \n",
    "        for gnfr in gnfr_list:\n",
    "            \n",
    "            ## Loop\n",
    "            c_gnfr = gnfr + \"_c\"\n",
    "            r_gnfr = gnfr + \"_r\"\n",
    "\n",
    "            if (merge_df2[r_gnfr].sum() != 0) & (merge_df2[r_gnfr].sum() != 0):\n",
    "            \n",
    "                stats = pd.DataFrame(df_var, columns = ['pollutant','R2','R2adj','obs','country_iso2'])\n",
    "                stats['pollutant'] = poll\n",
    "                stats['country_iso2'] = country_iso2\n",
    "                stats['gnfr'] = gnfr\n",
    "\n",
    "\n",
    "                ## Create the regression model\n",
    "                regression = smf.ols(str(c_gnfr+\"~\"+r_gnfr), merge_df2)\n",
    "                ols_fit = regression.fit()\n",
    "                # All the results in detail (it can be printed)\n",
    "                ols_res = ols_fit.summary()\n",
    "\n",
    "                # print(ols_res.summary())\n",
    "\n",
    "                print(\"Results for: \"+poll)\n",
    "                print(\"R2    \" + str(round(ols_fit.rsquared,2)))\n",
    "#                 print(\"R2adj \" + str(round(ols_fit.rsquared_adj,2)))\n",
    "                print(ccountry)\n",
    "                print(\"n.obs \" + str(int(ols_fit.nobs)))\n",
    "\n",
    "                stats[\"R2\"] = (round(ols_fit.rsquared,2))\n",
    "                stats[\"R2adj\"] = (round(ols_fit.rsquared_adj,2))\n",
    "                stats[\"obs\"] = (int(ols_fit.nobs))\n",
    "#                 stats_tot = stats_tot.append(stats)\n",
    "\n",
    "                # Add column with fitted values and residuals\n",
    "                merge_df2[('yhat_'+poll)] = ols_fit.fittedvalues\n",
    "                merge_df2[('res_'+poll)] = ols_fit.resid\n",
    "\n",
    "                std_res = merge_df2[('res_'+poll)].std()\n",
    "                merge_df2[('res_std_'+poll)] = merge_df2[('res_'+poll)]/std_res\n",
    "\n",
    "\n",
    "                flag_res_h = merge_df2[(merge_df2[\"res_std_\"+poll] >= 3)]\n",
    "                flag_res_l = merge_df2[(merge_df2[\"res_std_\"+poll] <= -3)]\n",
    "\n",
    "\n",
    "                # best fit polynomials\n",
    "\n",
    "                c_array = merge_df2[c_gnfr]\n",
    "                r_array = merge_df2[r_gnfr]\n",
    "\n",
    "                # Calculate the polynomial that fits\n",
    "                merge_fit = np.polyfit(r_array, c_array, 1)\n",
    "\n",
    "                ### Plot\n",
    "                # Get the right positon for the formula\n",
    "                max_val1 = merge_df2[c_gnfr].max()\n",
    "                max_val2 = merge_df2[r_gnfr].max()\n",
    "                up_pos = max_val1 * 0.18\n",
    "                right_pos = max_val2 * 0.75\n",
    "                up_pos2 = max_val1 * 0.25\n",
    "                right_pos2 = max_val2 * 0.75\n",
    "                up_pos3 = max_val1 * 0.32\n",
    "                right_pos3 = max_val2 * 0.75\n",
    "\n",
    "                c_poll = c_gnfr\n",
    "                r_poll = r_gnfr\n",
    "\n",
    "                rc['font.family'] = \"sans-serif\"\n",
    "                font = \"Roboto\"\n",
    "                # Scatter plots.\n",
    "                ax1 = merge_df2.plot(kind='scatter', x=r_poll, y=c_poll, color='blue', alpha=0.4, figsize=(10 ,7))\n",
    "                ax2 = flag_res_l.plot(kind='scatter', x=r_poll, y=c_poll, color='purple', alpha=0.8, figsize=(10 ,7), ax=ax1)\n",
    "                flag_res_h.plot(kind='scatter', x=r_poll, y=c_poll, color='red', alpha=0.8, figsize=(10 ,7), ax=ax2)\n",
    "\n",
    "                # # regression lines\n",
    "                plt.plot(merge_df2[c_poll], merge_fit[0] * merge_df2[c_poll] + merge_fit[1], color='darkblue', linewidth=0.4)\n",
    "\n",
    "                # # regression equations\n",
    "                plt.text(right_pos, up_pos , 'y={:.0f}+{:.2f}*x'.format(merge_fit[1], merge_fit[0]), color='darkblue', alpha=0.8, fontname=\"Computer Modern\", size=16)\n",
    "                R2adj = (\"R2 = \" + str(round(ols_fit.rsquared,2)))\n",
    "                plt.text(right_pos2, up_pos2, R2adj, color='darkblue', alpha=0.8, fontname=\"Computer Modern\", size=16)\n",
    "                obs = (\"n.obs = \" + str(int(ols_fit.nobs)))\n",
    "                plt.text(right_pos3, up_pos3, obs, color='darkblue', alpha=0.8, fontname=\"Computer Modern\", size=16)\n",
    "\n",
    "\n",
    "                # # legend, title and labels.\n",
    "                plt.legend(labels=['Emissions in ±3std','Emissions  <= 3std', 'Emissions  >= 3std', 'Regresion Line' ], loc=\"lower right\")\n",
    "                plt.title(('OLS-regression Reported-CAMS ' + poll + ' emissions (' + ccountry + ')'), fontname=font, size=20, pad=12)\n",
    "                plt.ylabel('CAMS (t)', fontname=font, size=15)\n",
    "                plt.xlabel('Reported (t)', fontname=font, size=15)\n",
    "\n",
    "                out_path1 = os.path.join(\"Q:/Delivery/GISdata/CLRTAP/Plots LPS/\" + \"LPS_ols_resid_\"+ccountry+\"_\" + year + \"_\"+gnfr+\"_\"+poll+\".png\") #### CHRIS BRING BACK IN\n",
    "                plt.savefig(out_path1 , dpi=150) # save as png\n",
    "                plt.show()\n",
    "\n",
    "                print(\"done\")\n",
    "\n",
    "\n",
    "        #(After the LOOP !!)\n",
    "        # output resid\n",
    "        \n",
    "#         out_path3 = os.path.join(ROOT,(\"resid_\"+country_iso2+\"_\"+poll+\"_\"+gnfr+\".csv\"))\n",
    "#         merge_df2.to_csv(out_path3 , index = False)\n",
    "    #     # output stats\n",
    "    #     out_path4 = os.path.join(out_base,country,(\"stats_\"+country+\".csv\"))\n",
    "    #     stats.to_csv(out_path4 , index = False)\n",
    "\n",
    "        # Apend datasets\n",
    "        \n",
    "#         stats_tot = stats_tot.append(stats)\n",
    "#         std_res_tot = std_res_tot.append(merge_df2)\n",
    "\n",
    "    \n",
    "# out_path (After the LOOP !!)\n",
    "# out_path5 = os.path.join(ROOT,\"output_r2\",(\"stats_tot_nl.csv\"))  #### CHRIS BRING BACK IN\n",
    "# stats_tot.to_csv(out_path5 , index = True)                       #### CHRIS BRING BACK IN\n",
    "\n",
    "# out_path6 = os.path.join(out_base,(\"std_res_total_\"+user+\".csv\"))\n",
    "# std_res_tot.to_csv(out_path6 , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fd1e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
